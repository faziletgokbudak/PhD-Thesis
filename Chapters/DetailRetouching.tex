\chapter{One-shot Detail Retouching}\label{one-shot}

Whether it is a human face we are examining or a butterfly wing with colourful tiny structures, details are the essential components defining aesthetics and identity. They drop hints about several aspects of the subjects, such as wrinkles pointing to either the rough age of the person or their emotional status, scratches describing the roughness of a material surface, or flyaway hair strands implying windy weather. When we capture a close-up photograph of a real-world scene, these details dominate the overall vibe of the scene, which consequently reflects on the appearance in photographs. As tiny as they are, however, editing these details is extremely challenging with a data-efficient learning-based approach due to the scarce number of pixels belonging to fine details. This chapter explores a detail editing task, photo retouching, and presents a novel learning-based framework that learns the transfers in intricate details from a single example pair.

Photo retouching is a challenging task for novice users, as it requires expert knowledge and advanced tools. Photographers often spend a significant amount of time producing high-quality retouched photos with intricate details. This chapter introduces a one-shot learning-based technique to automatically retouch details of an input image based on just a single pair of before and after example images. This approach provides accurate and generalisable detail edit transfer to new images, utilising a new representation for image-to-image maps. Specifically, I present neural field-based transformation blending in the patch space, which defines patch-to-patch transformations for each frequency band. This parametrisation of the map, with anchor transformations, associated weights, and spatio-spectrally localised patches, allows us to capture details effectively while remaining generalisable. I evaluate the proposed technique on both known ground truth filters and artist retouching edits. Our method accurately transfers complex detail retouching edits.

\begin{figure}
  \includegraphics[width=\textwidth]{Chapters/detail-retouching-figs/teaser_CVMP.pdf}
  \caption{The one-shot technique automatically transfers retouching edits to new images by learning the desired edits from one example \textit{before-after} pair (insets). The transferred edits accurately shape intricate details such as wrinkles, dark spots, strands of hair, or eyelashes, as shown in the input (top) and retouched (bottom) pairs. Images from [Jenavieve (top-left), Logan ProPro (top-left, inset), Marissa Oosterlee (top-middle). (CC-BY)].}
  % \Description{Our technique automatically transfers retouching edits to new images by learning the desired edits from one example \textit{before-after} pair (insets). The transferred edits accurately capture intricate details such as wrinkles, dark spots, strands of hair, or eyelashes, as shown in the input (top) and retouched (bottom) pairs.}
  \label{fig:DRteaser}
\end{figure}


% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}



\input{Chapters/detail-retouching-secs/Introduction}

\input{Chapters/detail-retouching-secs/RelatedWork}


\input{Chapters/detail-retouching-secs/Methodology}


\input{Chapters/detail-retouching-secs/Results}


\section{Summary}
%\TODO{Requires connection with the main theme of the thesis -- the first paragraph of the chapter and Introduction should help.}
In a photograph, details can reveal key features about subjects, such as identity-related attributes, or simply highlight aesthetic beauty. Transferring edits to such fine details is highly desirable, as it enhances the overall look or style of a scene and its visual appeal. However, these creative edits often require significant effort, involving adjustments to both global features like brightness and contrast, as well as local regions to remove imperfections or emphasise specific areas. Professionals can spend hours producing these edits. Therefore, this chapter introduced a neural field-based technique for example-based automatic image retouching, motivated by the need to automatically replicate a specific style or retouch. By formulating the transfer problem in patch space, I demonstrated that blending multiple transformation matrices with patch-adaptive weights can effectively learn an accurate and generalisable mapping. This allowed us to use images of various scenes, people, views, and environmental conditions as the example pair and input. The technique's utility was illustrated through various retouching examples and edge-aware image processing filters. The proposed image mapping representation has potential applications in many other image processing tasks and could be extended to scene-level texture editing.

% \begin{figure*}%[th]
%   \centering
%   \includegraphics[height=0.8\textheight, width=\linewidth,keepaspectratio]{Images/AdditionalResults_op2.pdf}
%   \caption{
%            Retouches reproduced by our algorithm based on single before-after pairs. }
%            \label{fig:AdditionalRes}%
% \end{figure*}

% \section{Appendices}
